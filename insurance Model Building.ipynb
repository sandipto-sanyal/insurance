{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Objective\n",
    "This is a dataset taken from <b>UCI Machine Learning</b> repository\n",
    "<br>\n",
    "Link: https://archive.ics.uci.edu/ml/datasets/Insurance+Company+Benchmark+%28COIL+2000%29\n",
    "<br>\n",
    "<b>Data Set Information:</b>\n",
    "<br>\n",
    "Information about customers consists of <font color=\"red\">86</font> variables and includes product usage data and socio-demographic data derived from zip area codes. The data was supplied by the <font color=\"red\">Dutch data mining company Sentient Machine Research</font> and is based on a real world business problem. The training set contains over <font color=\"red\">5000</font> descriptions of customers, including the information of whether or not they have a caravan insurance policy. A test set contains <font color=\"red\">4000</font> customers of whom only the organisers know if they have a caravan insurance policy.\n",
    "<br>\n",
    "<br>\n",
    "<b>Objective:</b> Our objective is to predict whether a customer will like a \"Caravan policy\"\n",
    "<br>\n",
    "## How this dataset will address our idea in Accenture Innovation contest?\n",
    "In this contest we addressed the challenge faced by Indian insurance companies to chose the right product for the right customer. This sample POC has a similar business objective where we are trying to predict whether a customer with a particular feature will like a particular product (in our case \"A Caravan Policy) or not.\n",
    "\n",
    "## Approach to the problem\n",
    "We will take 2 steps approach towards this problem<br>\n",
    "i) Exploratory Data Analysis to find out the relevant columns which we will be taking in as input<br>\n",
    "ii) Classification Model building and performance evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r'F:\\Machine learning\\Accenture Innovation'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our modified training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_modified.csv')\n",
    "test = pd.read_csv('test_modified.csv')\n",
    "test_eval = pd.read_csv('tictgts2000.txt',names=['CARAVAN'])\n",
    "test = pd.concat([test,test_eval],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining both train and test set for performing Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.concat([train,test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MOSTYPE', 'MAANTHUI', 'MGEMOMV', 'MGEMLEEF', 'MGODRK', 'MGODPR',\n",
      "       'MGODOV', 'MGODGE', 'MRELGE', 'MRELSA', 'MFALLEEN', 'MFGEKIND',\n",
      "       'MOPLHOOG', 'MOPLMIDD', 'MOPLLAAG', 'MBERHOOG', 'MBERZELF', 'MBERBOER',\n",
      "       'MBERMIDD', 'MBERARBG', 'MBERARBO', 'MSKA', 'MSKB1', 'MSKB2', 'MSKC',\n",
      "       'MSKD', 'MHHUUR', 'MAUT1', 'MAUT2', 'MAUT0', 'MZFONDS', 'MINKM30',\n",
      "       'MINK3045', 'MINK4575', 'MINK7512', 'MINK123M', 'MINKGEM', 'MKOOPKLA',\n",
      "       'PWAPART', 'CARAVAN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(temp_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hot Encoding\n",
    "As per the business data description Hot Encoding will be done on the following columns<br>\n",
    "i) MOSTYPE: This is a category \"Customer subtype\"<br>\n",
    "Since other categories denote ranges of Age, Percentages hence we are leaving those columns as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.get_dummies(temp_df,drop_first=True,columns=['MOSTYPE'])\n",
    "#dividing the train and test datasets again after performing hot encoding\n",
    "train = temp_df.iloc[:5822,:]\n",
    "test = temp_df.iloc[5822:len(temp_df),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the dataframes to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train.drop(columns=['CARAVAN']))\n",
    "y_train = np.array(train.CARAVAN)\n",
    "X_test = np.array(test.drop(columns=['CARAVAN']))\n",
    "y_test = np.array(test.CARAVAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying standard scaler to standardize the values of columns\n",
    "Standardization is an important part before feeding into ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing SMOTE to reduce imbalance in training dataset\n",
    "Since the training DS is a highly imbalanced one we are performing Oversampling of minority data (people who have liked caravan policy) using SMOTE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-d2ce56a03c85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 12, sampling_strategy = 1.0)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "unique, counts = np.unique(y_res, return_counts=True)\n",
    "print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(choice):\n",
    "    if choice == 1:\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "    elif choice == 2:\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "    elif choice == 3:\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 2\n",
    "fit = classifier(choice).fit(X_train,y_train)\n",
    "y_pred = fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics\n",
    "Here we evaluate the performances of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3690   72]\n",
      " [ 222   16]]\n",
      "Accuracy_score: 0.93\n",
      "Precision_score: 0.18\n",
      "Recall_score: 0.07\n",
      "f1_score: 0.10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "y_test1 = y_test\n",
    "cm = confusion_matrix(y_test1, y_pred)\n",
    "print('Confusion matrix:\\n' + str(cm))\n",
    "print('Accuracy_score: %.2f' %(accuracy_score(y_test1, y_pred)))\n",
    "print('Precision_score: %.2f' %(precision_score(y_test1, y_pred))) # tp / (tp + fp)\n",
    "print('Recall_score: %.2f' %(recall_score(y_test1, y_pred))) # tp / (tp + fn)\n",
    "print('f1_score: %.2f' %(f1_score(y_test1, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1]\n",
      " [3912   88]]\n",
      "[[   0    1]\n",
      " [3762  238]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "print(np.asarray((unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3762\n",
       "1     238\n",
       "Name: CARAVAN, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.CARAVAN.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
