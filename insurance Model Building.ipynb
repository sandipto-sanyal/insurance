{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Objective\n",
    "This is a dataset taken from <b>UCI Machine Learning</b> repository\n",
    "<br>\n",
    "Link: https://archive.ics.uci.edu/ml/datasets/Insurance+Company+Benchmark+%28COIL+2000%29\n",
    "<br>\n",
    "<b>Data Set Information:</b>\n",
    "<br>\n",
    "Information about customers consists of <font color=\"red\">86</font> variables and includes product usage data and socio-demographic data derived from zip area codes. The data was supplied by the <font color=\"red\">Dutch data mining company Sentient Machine Research</font> and is based on a real world business problem. The training set contains over <font color=\"red\">5000</font> descriptions of customers, including the information of whether or not they have a caravan insurance policy. A test set contains <font color=\"red\">4000</font> customers of whom only the organisers know if they have a caravan insurance policy.\n",
    "<br>\n",
    "<br>\n",
    "<b>Objective:</b> Our objective is to predict whether a customer will like a \"Caravan policy\"\n",
    "<br>\n",
    "## How this dataset will address our idea in Accenture Innovation contest?\n",
    "In this contest we addressed the challenge faced by Indian insurance companies to chose the right product for the right customer. This sample POC has a similar business objective where we are trying to predict whether a customer with a particular feature will like a particular product (in our case \"A Caravan Policy) or not.\n",
    "\n",
    "## Approach to the problem\n",
    "We will take 2 steps approach towards this problem<br>\n",
    "i) Exploratory Data Analysis to find out the relevant columns which we will be taking in as input<br>\n",
    "ii) Classification Model building and performance evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r'F:\\Machine learning\\Accenture Innovation'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our modified training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_modified.csv')\n",
    "test = pd.read_csv('test_modified.csv')\n",
    "test_eval = pd.read_csv('tictgts2000.txt',names=['CARAVAN'])\n",
    "test = pd.concat([test,test_eval],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining both train and test set for performing Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.concat([train,test],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hot Encoding\n",
    "As per the business data description Hot Encoding will be done on the following columns<br>\n",
    "i) MOSTYPE: This is a category \"Customer subtype\"<br>\n",
    "Since other categories denote ranges of Age, Percentages hence we are leaving those columns as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.get_dummies(temp_df,drop_first=True,columns=['MOSTYPE'])\n",
    "#dividing the train and test datasets again after performing hot encoding\n",
    "train = temp_df.iloc[:5822,:]\n",
    "test = temp_df.iloc[5822:len(temp_df),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the dataframes to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train.drop(columns=['CARAVAN']))\n",
    "y_train = np.array(train.CARAVAN)\n",
    "X_test = np.array(test.drop(columns=['CARAVAN']))\n",
    "y_test = np.array(test.CARAVAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying standard scaler to standardize the values of columns\n",
    "Standardization is an important part before feeding into ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing SMOTE to reduce imbalance in training dataset\n",
    "Since the training DS is a highly imbalanced one we are performing Oversampling of minority data (people who have liked caravan policy) using SMOTE algorithm<br>\n",
    "SMOTE = Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1]\n",
      " [5474 5474]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10948"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 12)\n",
    "X_res, y_res = smote.fit_sample(X_train, y_train)\n",
    "unique, counts = np.unique(y_res, return_counts=True)\n",
    "print(np.asarray((unique, counts)))\n",
    "len(X_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(choice):\n",
    "    if choice == 1:\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "    elif choice == 2:\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "    elif choice == 3:\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "    elif choice == 4:\n",
    "        return ANN()\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN():\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 39, init = 'uniform', activation = 'relu', input_dim = X_res.shape[1]))\n",
    "    classifier.add(Dense(output_dim = 39, init = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 4\n",
    "fit = classifier(choice).fit(X_res,\n",
    "                             y_res,\n",
    "                             batch_size = 10,\n",
    "                             nb_epoch = 100\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=77, units=39, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=39, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier(choice).predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics\n",
    "Here we evaluate the performances of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 764 2998]\n",
      " [  60  178]]\n",
      "Accuracy_score: 0.24\n",
      "Precision_score: 0.06\n",
      "Recall_score: 0.75\n",
      "f1_score: 0.10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "y_test1 = y_test\n",
    "cm = confusion_matrix(y_test1, y_pred)\n",
    "print('Confusion matrix:\\n' + str(cm))\n",
    "print('Accuracy_score: %.2f' %(accuracy_score(y_test1, y_pred)))\n",
    "print('Precision_score: %.2f' %(precision_score(y_test1, y_pred))) # tp / (tp + fp)\n",
    "print('Recall_score: %.2f' %(recall_score(y_test1, y_pred))) # tp / (tp + fn)\n",
    "print('f1_score: %.2f' %(f1_score(y_test1, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred distribution\n",
      "[[   0    1]\n",
      " [ 301 3699]]\n",
      "y_test actual distribution\n",
      "[[   0    1]\n",
      " [3762  238]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "print('y_pred distribution')\n",
    "print(np.asarray((unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print('y_test actual distribution')\n",
    "print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07017544, 0.04761905, 0.        , 0.04347826, 0.04      ,\n",
       "       0.03921569, 0.04545455, 0.        , 0.04545455, 0.04761905])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "f1 = cross_val_score(estimator = fit, X = X_train, y = y_train, cv = 10, scoring='f1')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 77)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
